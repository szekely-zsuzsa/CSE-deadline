---
title: "Srtoop deadline: analysis"
author: "Zsuzsa Szekely"
output: html_document: default
editor_options:
  chunk_output_type: console
---
## Load packages

```{r load packages, warning = FALSE, message = FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, osfr, lme4, BayesFactor, DescTools, sjstats, car, broom, cowplot)
```

## Load helper functions

```{r load helper functions}
source("R/utils.R")
```

# Import data

```{r, message = FALSE, warning = FALSE}
processed_rt <- read_tsv("data/deadline/processed/processed_data_rt.tsv")
processed_acc <- read_tsv("data/deadline/processed/processed_data_acc.tsv")
```

# Descriptive statistics of the sample size
## Number of participants left after exclusion

The number of participants should be the same for the reaction time and the the accuracy as well

```{r, warning = FALSE}
processed_rt %>% 
  distinct(participant_id) %>% 
  count()

processed_acc %>% 
  distinct(participant_id) %>% 
  count()
```

## Number of responses after exclusion
### For the reaction time analysis

```{r, warning = FALSE}
processed_rt %>%
  count()
```

### For the accuracy analysis

```{r, warning = FALSE}
processed_acc %>%
  count()
```

***

# Checking CSE for reaction time
## Figures of CSE for reaction time

```{r, eval= FALSE}
# prepare the cse rt plot
cse_plot_rt_data <-
  processed_rt %>%
  # create congruency text variables
  mutate(isPrevCongruent = case_when(isPrevCongruent ==  0L ~ "Incongruent",
                                     isPrevCongruent ==  1L ~ "Congruent"),
         isCongruent = case_when(congruency ==  "inc" ~ "Incongruent",
                                 congruency ==  "con" ~ "Congruent")) %>%
  # calculate mean rt of each participant
  group_by(participant_id, condition) %>%
  mutate(participant_mean_rt = mean(reaction_time, na.rm = T)) %>%
  # calculate the mean, sd and se of rt incuding all participants' results
  group_by(condition) %>%
  mutate(N = n(),
         mean_rt = mean(participant_mean_rt, na.rm = T),
         sd_rt = sd(participant_mean_rt, na.rm = T),
         se_rt = sd_rt / sqrt(N))

# creating the plot
cse_plot_rt <- cse_plot_rt_data %>% 
  ggplot(aes(x = isPrevCongruent, y = mean_rt,
             color = isCongruent,
             group = isCongruent)) +
  geom_path() +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = mean_rt - se_rt, ymax = mean_rt + se_rt), width=.1) +
  scale_color_manual(values=c("#A8D08C", "#F26C4F")) +
  # scale_y_continuous(limits = c(500, 600)) +
  # scale_x_discrete(expand=c(1, 0)) +
  # ggtitle(stringr::str_to_title()) +
  xlab("Congruency of the previous trial")+
  ylab("Mean reaction time (ms)") +
  guides(color = guide_legend(title="Congruency of \n the current trial")) 
  # + theme(legend.position = c(0.85, 0.5),
  #       axis.line = element_line(color = "black"),
  #       panel.background = element_blank(),
  #       legend.key = element_rect(colour = "transparent", fill = "white"))
```

## Saving the rt CSE figure

```{r, eval= FALSE}
ggsave("figures/deadline/rt_cse.png", width = 14.4, height = 8, plot = last_plot())
```

## Hungarian figures of CSE for reaction time

```{r, eval= FALSE}
# prepare the cse rt plot
cse_plot_rt_data_hun <-
  processed_rt %>%
  # create congruency text variables
  mutate(isPrevCongruent = case_when(isPrevCongruent ==  0L ~ "Inkongruens",
                                     isPrevCongruent ==  1L ~ "Kongruens"),
         isCongruent = case_when(congruency ==  "inc" ~ "Inkongruens",
                                 congruency ==  "con" ~ "Kongruens")) %>%
  # calculate mean rt of each participant
  group_by(participant_id, condition) %>%
  mutate(participant_mean_rt = mean(reaction_time, na.rm = T)) %>%
  # calculate the mean, sd and se of rt incuding all participants' results
  group_by(condition) %>%
  mutate(N = n(),
         mean_rt = mean(participant_mean_rt, na.rm = T),
         sd_rt = sd(participant_mean_rt, na.rm = T),
         se_rt = sd_rt / sqrt(N))

# creating the plot
cse_plot_rt_hun <- cse_plot_rt_data_hun %>% 
  ggplot(aes(x = isPrevCongruent, y = mean_rt,
             color = isCongruent,
             group = isCongruent)) +
  geom_path() +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = mean_rt - se_rt, ymax = mean_rt + se_rt), width=.1) +
  scale_color_manual(values=c("#A8D08C", "#F26C4F")) +
  # scale_y_continuous(limits = c(500, 600)) +
  # scale_x_discrete(expand=c(1, 0)) +
  # ggtitle(stringr::str_to_title()) +
  xlab("Előző próba kongruenciája")+
  ylab("Átlagos reakcióidő (ms)") +
  guides(color = guide_legend(title="Próba \nkongruenciája")) 
  # + theme(legend.position = c(0.85, 0.5),
  #       axis.line = element_line(color = "black"),
  #       panel.background = element_blank(),
  #       legend.key = element_rect(colour = "transparent", fill = "white"))
```

## Saving the rt CSE Hungarian figures

```{r, eval= FALSE}
ggsave("figures/deadline/rt_cse_hun.png", width = 14.4, height = 8, plot = last_plot())
```

# Checking CSE for accuracy in
## Figures of CSE for accuracy

```{r, eval= FALSE}
# prepare the cse rt plot
cse_plot_acc_data <-
  processed_acc %>%
  # create congruency text variables
  mutate(isPrevCongruent = case_when(isPrevCongruent ==  0L ~ "Incongruent",
                                     isPrevCongruent ==  1L ~ "Congruent"),
         isCongruent = case_when(congruency ==  "inc" ~ "Incongruent",
                                 congruency ==  "con" ~ "Congruent")) %>%
  # calculate mean rt of each participant
  group_by(participant_id, condition) %>%
  mutate(participant_mean_acc = mean(correct, na.rm = T)) %>%
  # calculate the mean, sd and se of rt incuding all participants' results
  group_by(condition) %>%
  mutate(N = n(),
         mean_acc = mean(participant_mean_acc, na.rm = T)*100,
         sd_acc = sd(participant_mean_acc, na.rm = T),
         se_acc = sd_acc / sqrt(N))

# creating the plot
cse_plot_acc <- cse_plot_acc_data %>% 
  ggplot(aes(x = isPrevCongruent, y = mean_acc,
             color = isCongruent,
             group = isCongruent)) +
  geom_path() +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = mean_acc - se_acc, ymax = mean_acc + se_acc), width=.1) +
  scale_color_manual(values=c("#A8D08C", "#F26C4F")) +
  # scale_y_continuous(limits = c(500, 600)) +
  # scale_x_discrete(expand=c(1, 0)) +
  # ggtitle(stringr::str_to_title()) +
  xlab("Congruency of the previous trial")+
  ylab("Accuracy (%)") +
  guides(color = guide_legend(title="Congruency of \n the current trial")) 
  # + theme(legend.position = c(0.85, 0.5),
  #       axis.line = element_line(color = "black"),
  #       panel.background = element_blank(),
  #       legend.key = element_rect(colour = "transparent", fill = "white"))
```

## Saving the accuracy CSE figure

```{r, eval= FALSE}
ggsave("figures/deadline/acc_cse.png", width = 14.4, height = 8, plot = last_plot())
```

## Hungarian figures of CSE for accuracy

```{r, eval= FALSE}
# prepare the cse rt plot
cse_plot_acc_data_hun <-
  processed_acc %>%
  # create congruency text variables
  mutate(isPrevCongruent = case_when(isPrevCongruent ==  0L ~ "Inkongruens",
                                     isPrevCongruent ==  1L ~ "Kongruens"),
         isCongruent = case_when(congruency ==  "inc" ~ "Inkongruens",
                                 congruency ==  "con" ~ "Kongruens")) %>%
  # calculate mean rt of each participant
  group_by(participant_id, condition) %>%
  mutate(participant_mean_acc = mean(correct, na.rm = T)) %>%
  # calculate the mean, sd and se of rt incuding all participants' results
  group_by(condition) %>%
  mutate(N = n(),
         mean_acc = mean(participant_mean_acc, na.rm = T)*100,
         sd_acc = sd(participant_mean_acc, na.rm = T),
         se_acc = sd_acc / sqrt(N))

# creating the plot
cse_plot_acc <- cse_plot_acc_data_hun %>% 
  ggplot(aes(x = isPrevCongruent, y = mean_acc,
             color = isCongruent,
             group = isCongruent)) +
  geom_path() +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = mean_acc - se_acc, ymax = mean_acc + se_acc), width=.1) +
  scale_color_manual(values=c("#A8D08C", "#F26C4F")) +
  # scale_y_continuous(limits = c(500, 600)) +
  # scale_x_discrete(expand=c(1, 0)) +
  # ggtitle(stringr::str_to_title()) +
  xlab("Előző próba kongruenciája")+
  ylab("Pontosság (%)") +
  guides(color = guide_legend(title="Próba \nkongruenciája")) 
  # + theme(legend.position = c(0.85, 0.5),
  #       axis.line = element_line(color = "black"),
  #       panel.background = element_blank(),
  #       legend.key = element_rect(colour = "transparent", fill = "white"))
```

## Saving the Hungarian accuracy CSE figure

```{r, eval= FALSE}
ggsave("figures/deadline/acc_cse_hun.png", width = 14.4, height = 8, plot = last_plot())
```








# Reaction time analyis
## I. analysis: Testing whether the CSE was present in the task
### Preprocessing data

We are calculating mean reaction time for the analysis for each participant in each condition.

```{r, warning = FALSE}
processed_rt <- processed_rt %>% 
  group_by(participant_id, condition) %>% 
  mutate(rtConditionalMean = mean(reaction_time, na.rm = TRUE)) %>%
  ungroup() %>% 
  mutate(isCongruent = as.factor(congruency),
         isPrevCongruent = as.factor(isPrevCongruent),
         participant_id = as.factor(participant_id))
```

We are calculating the main congruency effect of the current (n) trial, the main congruency effect of the previous trial (n-1) and the interaction effect (CSE) between them for each participant.
```{r}
processed <-
  processed %>% 
  mutate(w2_rt_effect_data = map(w2_rt_data,
                                 . %>%
                                    mutate(condition = case_when(isPrevCongruent == 0L & isCongruent == 0L ~ "ii",
                                                                 isPrevCongruent == 0L & isCongruent == 1L ~ "ic",
                                                                 isPrevCongruent == 1L & isCongruent == 0L ~ "ci",
                                                                 isPrevCongruent == 1L & isCongruent == 1L ~ "cc",
                                                                 TRUE ~ NA_character_)) %>%
                                    select(-isPrevCongruent, -isCongruent) %>%
                                    spread(key = condition, value = rtConditionalMean) %>%
                                    mutate(congruencyEffect = ((ci + ii) / 2) - ((cc + ic) / 2),
                                           prevCongruencyEffect = ((ci + cc) / 2) - ((ii + ic) / 2),
                                           cseEffect = (ci - cc) - (ii - ic))))

rt_effect_data <- processed_rt %>% 
  spread(key = condition, value = rtConditionalMean) %>%
  mutate(congruencyEffect = ((ci + ii) / 2) - ((cc + ic) / 2),
         prevCongruencyEffect = ((ci + cc) / 2) - ((ii + ic) / 2),
         cseEffect = (ci - cc) - (ii - ic))
```

### Running the analysis on wave2 data

We are running a 2 × 2 repeated-measures ANOVA per task with mean RT as dependent variable. The two factors of the ANOVA are Previous Trial Congruency (congruent, incongruent) and Current Trial Congruency (congruent, incongruent).

```{r}
processed <-
  processed %>% 
  mutate(w2_anova_rt = map(w2_rt_data,
                        ~ aov(rtConditionalMean ~ isCongruent * isPrevCongruent + Error(participant_id / (isCongruent * isPrevCongruent)), data = .x)))

# Print results with names
processed$w2_anova_rt %>% 
  set_names(., processed$task) %>% 
  map(., summary)
```

The interaction was only significant for the first task, the primeprobe task.

We are calculating the partial eta square as an effect size estimate for the ANOVA.

```{r}
processed <-
  processed %>% 
  mutate(w2_anova_rt_eta = map(w2_anova_rt,
                            ~ eta_sq(.x, partial = TRUE)))

# Print results with names
processed$w2_anova_rt_eta %>% 
  set_names(., processed$task)
```

### Calculating Bayes factors
#### Preprocessing data for the Bayes factor analysis

We are substracting the F values for each effect (main congruency effect of current trial, main congruency effect of previous trial and interaction effect) from the ANOVA.

```{r}
processed <-
  processed %>% 
  mutate(w2_anova_rt_f = map(w2_anova_rt,
                             . %>%
                                broom::tidy() %>%
                                select(term, statistic) %>%
                                transmute(term = case_when(term == "isCongruent" ~ "mainEffectIsCongruent",
                                                           term == "isPrevCongruent" ~ "mainEffectIsPrevCongruent",
                                                           term == "isCongruent:isPrevCongruent" ~ "interactionEffect",
                                                           term == "Residuals" ~ term),
                                          fValue = statistic) %>%
                                filter(!is.na(fValue))))
```

We are calculating the mean effects (main congruency effect of current trial, main congruency effect of previous trial and interaction effect) for each task.

```{r}
processed <-
  processed %>% 
  mutate(w2_anova_rt_raw_effect = map(w2_rt_effect_data, 
                                   . %>% 
                                     summarise(mainEffectIsCongruent = mean(congruencyEffect, na.rm = T),
                                               mainEffectIsPrevCongruent = mean(prevCongruencyEffect, na.rm = T),
                                               interactionEffect = mean(cseEffect, na.rm = T),
                                               nParticipant = n()) %>%
                                     gather(key = "term", value = "rawEffect", -nParticipant)))
#We can create a table with the magnitude of the CSE across tasks here, right?
```

We are adding the calucalted F-values for each effect to the calculated mean effects.

```{r}
processed <-
  processed %>% 
  mutate(w2_anova_rt_raw_effect = map2(w2_anova_rt_raw_effect, w2_anova_rt_f,
                                    ~ inner_join(.x, .y, by = "term")))
```

Calculating the SEs.

```{r}
processed <- 
  processed %>% 
  mutate(w2_anova_rt_raw_effect = map(w2_anova_rt_raw_effect,
                                   . %>% 
                                     mutate(se = rawEffect / sqrt(fValue))))
```

Preprocessing effect sizes that Weissman et al. (2014) found for the H1 model of the Bayes factor analysis.

```{r}
original_rt_effect <-
  original %>% 
  filter(measure == "rt") %>% 
  select(task, congruency, cse) %>% 
  gather(key = "term", value = "originalRawEffect", -task) %>%
  mutate(term = case_when(term == "congruency" ~ "mainEffectIsCongruent",
                          term == "cse" ~ "interactionEffect")) %>% 
  group_by(task) %>% 
  nest() %>% 
  rename(original_effect_reaction_time = data)
```

Joining the effect sizes of the replicated study with the effect sizes of the current study.

```{r}
processed <-
  processed %>%
  mutate(task = as.character(task)) %>% # vector needs to be character class (instead of a list) for joining
  left_join(., original_rt_effect, by = "task") %>% 
  mutate(w2_anova_rt_bf_effect = map2(w2_anova_rt_raw_effect, original_effect_reaction_time,
                              ~ left_join(.x, .y, by = "term")))
```

Parameters for calculating the Bayes-factor

```{r, warning = FALSE}
map(processed$w2_anova_rt_bf_effect, print)
```

#### Calculating the Bayes factor
##### For the interaction effect

A half-normal distribution is used with a mode of 0 and a SD equal to the half of the congruency effect (in ms) for the particular task in the original data set by Weissman et al. (2014) to model the prediction of the interaction effect. 

```{r}
processed <-
  processed %>%
  mutate(w2_bf_interaction_rt = map(w2_anova_rt_bf_effect,
                                 ~ Bf(sd = .x$se[3],
                                      obtained = .x$rawEffect[3],
                                      dfdata = .x$nParticipant[1] - 1,
                                      meanoftheory = 0,
                                      sdtheory = .x$originalRawEffect[1] / 2,
                                      dftheory = 10^10,
                                      tail = 1)))

# Print results with names
processed$w2_bf_interaction_rt %>% 
  set_names(., processed$task)
```

##### For the main congruency effect of the current trial

To test the congruency main effect, the SD of the H1 model is set to the congruency effect reported by Weissman et al. (2014) for the given task. The other settings stay the same.

```{r}
processed <-
  processed %>%
  mutate(w2_bf_congruency_rt = map(w2_anova_rt_bf_effect,
                                ~ Bf(sd = .x$se[1],
                                     obtained = .x$rawEffect[1],
                                     dfdata = .x$nParticipant[1] - 1,
                                     meanoftheory = 0,
                                     sdtheory = .x$originalRawEffect[1],
                                     dftheory = 10^10,
                                     tail = 1)))

# Print results with names
processed$w2_bf_congruency_rt %>% 
  set_names(., processed$task)
```

### Follow up simple effects analysis
#### Running the analysis

If the Bayes factor is greater than the preset threshold of B = 3 for the interaction effect in a given task we run a simple effects analyses, contrasting current-congruent congruent (cC) and current-incongruent congruent (iC) trials.

```{r current congruent follow up comparison for rt}
processed <-
  processed %>% 
  mutate(w2_cong_post_rt = map(w2_rt_data,
                            . %>% 
                              filter(isCongruent == 1)),
         w2_cong_post_rt_test = map2(w2_cong_post_rt, task,
                                  ~ aov(rtConditionalMean ~ isPrevCongruent + Error(participant_id / isPrevCongruent), data = .x)))

# Print results with names
processed$w2_cong_post_rt_test %>% 
  set_names(., processed$task) %>% 
  map(., summary)
```

current-congruent incongruent (cI) and current-incongruent incongruent (iI) trials in another.

```{r current incongruent follow up comparison for rt}
processed <-
  processed %>% 
  mutate(w2_incong_post_rt = map(w2_rt_data,
                            . %>% 
                              filter(isCongruent == 0)),
         w2_incong_post_rt_test = map2(w2_incong_post_rt, task,
                                  ~ aov(rtConditionalMean ~ isPrevCongruent + Error(participant_id / isPrevCongruent), data = .x)))

# Print results with names
processed$w2_incong_post_rt_test %>% 
  set_names(., processed$task) %>% 
  map(., summary)
```

#### Brute force method for follow ups - setting up BF calculations ####

```{r}
primeprobe <- processed$w2_rt_effect_data[[1]]
flanker <- processed$w2_rt_effect_data[[2]]
stroop <- processed$w2_rt_effect_data[[3]]
simon <- processed$w2_rt_effect_data[[4]]

w2_current_cong_pp <- 
  t.test(primeprobe$ic, primeprobe$cc, paired = TRUE) %>% 
  broom::tidy()
w2_current_cong_fl <- 
  t.test(flanker$ic, flanker$cc, paired = TRUE) %>% 
  broom::tidy()
w2_current_cong_str <- 
  t.test(stroop$ic, stroop$cc, paired = TRUE) %>% 
  broom::tidy()
w2_current_cong_sim <- 
  t.test(simon$ic, simon$cc, paired = TRUE) %>% 
  broom::tidy()

w2_current_inc_pp <- 
  t.test(primeprobe$ci, primeprobe$ii, paired = TRUE) %>% 
  broom::tidy()
w2_current_inc_fl <- 
  t.test(flanker$ci, flanker$ii, paired = TRUE) %>% 
  broom::tidy()
w2_current_inc_str <- 
  t.test(stroop$ci, stroop$ii, paired = TRUE) %>% 
  broom::tidy()
w2_current_inc_sim <- 
  t.test(simon$ci, simon$ii, paired = TRUE) %>% 
  broom::tidy()
```

#### Calculating the Bayes factor for the follow up analysis

The prior H1 model is a half-normal distribution with a mode of 0 and an SD equal to half of the CSE estimate for that given task, i.e., the originally reported congruency effect divided by four.

##### Current congruent follow up analysis

```{r}
Bf(sd = w2_current_cong_pp$estimate / w2_current_cong_pp$statistic,
   obtained = w2_current_cong_pp$estimate,
   dfdata = w2_current_cong_pp$parameter,
   meanoftheory = 0,
   sdtheory = processed$w2_anova_rt_bf_effect[[1]]$originalRawEffect[1] / 4,
   dftheory = 10^10,
   tail = 1)
Bf(sd = w2_current_cong_fl$estimate / w2_current_cong_fl$statistic,
   obtained = w2_current_cong_fl$estimate,
   dfdata = w2_current_cong_fl$parameter,
   meanoftheory = 0,
   sdtheory = processed$w2_anova_rt_bf_effect[[2]]$originalRawEffect[1] / 4,
   dftheory = 10^10,
   tail = 1)
Bf(sd = w2_current_cong_str$estimate / w2_current_cong_str$statistic,
   obtained = w2_current_cong_str$estimate,
   dfdata = w2_current_cong_str$parameter,
   meanoftheory = 0,
   sdtheory = processed$w2_anova_rt_bf_effect[[3]]$originalRawEffect[1] / 4,
   dftheory = 10^10,
   tail = 1)
Bf(sd = w2_current_cong_sim$estimate / w2_current_cong_sim$statistic,
   obtained = w2_current_cong_sim$estimate,
   dfdata = w2_current_cong_sim$parameter,
   meanoftheory = 0,
   sdtheory = processed$w2_anova_rt_bf_effect[[4]]$originalRawEffect[1] / 4,
   dftheory = 10^10,
   tail = 1)
```

##### Current incongruent follow up analysis

```{r}
Bf(sd = w2_current_inc_pp$estimate / w2_current_inc_pp$statistic,
   obtained = w2_current_inc_pp$estimate,
   dfdata = w2_current_inc_pp$parameter,
   meanoftheory = 0,
   sdtheory = processed$w2_anova_rt_bf_effect[[1]]$originalRawEffect[1] / 4,
   dftheory = 10^10,
   tail = 1)
Bf(sd = w2_current_inc_fl$estimate / w2_current_inc_fl$statistic,
   obtained = w2_current_inc_fl$estimate,
   dfdata = w2_current_inc_fl$parameter,
   meanoftheory = 0,
   sdtheory = processed$w2_anova_rt_bf_effect[[2]]$originalRawEffect[1] / 4,
   dftheory = 10^10,
   tail = 1)
Bf(sd = w2_current_inc_str$estimate / w2_current_inc_str$statistic,
   obtained = w2_current_inc_str$estimate,
   dfdata = w2_current_inc_str$parameter,
   meanoftheory = 0,
   sdtheory = processed$w2_anova_rt_bf_effect[[3]]$originalRawEffect[1] / 4,
   dftheory = 10^10,
   tail = 1)
Bf(sd = w2_current_inc_sim$estimate / w2_current_inc_sim$statistic,
   obtained = w2_current_inc_sim$estimate,
   dfdata = w2_current_inc_sim$parameter,
   meanoftheory = 0,
   sdtheory = processed$w2_anova_rt_bf_effect[[4]]$originalRawEffect[1] / 4,
   dftheory = 10^10,
   tail = 1)
```

***
# Testing correlation of CSE between wave1 and wave2 rt data

```{r, warning = FALSE}
processed <-
  processed %>% 
  mutate(corr_data_rt = map(rt_data,
                       . %>%
                          group_by(wave, participant_id, isCongruent, isPrevCongruent) %>%
                          summarise(rtConditionalMean = mean(rt, na.rm = T)) %>%
                          ungroup() %>%
                          mutate(isCongruent = as.factor(isCongruent),
                                 isPrevCongruent = as.factor(isPrevCongruent),
                                 participant_id = as.factor(participant_id))))
```

## We are calculating the main congruency effect of the current (n) trial, the main congruency effect of the previous trial (n-1) and the interaction effect (CSE) between them for each participant in both waves.

```{r}
processed <-
  processed %>% 
  mutate(corr_effect_data_rt = map(corr_data_rt,

                              . %>%
                                 mutate(condition = case_when(isPrevCongruent == 0L & isCongruent == 0L ~ "ii",
                                                             isPrevCongruent == 0L & isCongruent == 1L ~ "ic",
                                                             isPrevCongruent == 1L & isCongruent == 0L ~ "ci",
                                                             isPrevCongruent == 1L & isCongruent == 1L ~ "cc",
                                                             TRUE ~ NA_character_)) %>%
                                 select(-isPrevCongruent, -isCongruent) %>%
                                 spread(key = condition, value = rtConditionalMean) %>%
                                 mutate(congruencyEffect = ((ci + ii) / 2) - ((cc + ic) / 2),
                                        prevCongruencyEffect = ((ci + cc) / 2) - ((ii + ic) / 2),
                                        cseEffect = (ci - cc) - (ii - ic))))

```

## Preprocessing df for correlation calculation

```{r}
processed <-
   processed %>% 
   mutate(corr_cse_data_rt = map(corr_effect_data_rt,
                              . %>% 
                                 select(wave, participant_id, cseEffect) %>%
                                 spread(key = wave, value = cseEffect) %>% 
                                 rename(w1_cse = `1`, w2_cse = `2`)))
```

## Calculating correlation

```{r}
processed <-
  processed %>% 
  mutate(corr_res_rt = map(corr_cse_data_rt,
                    ~ cor.test(.x$w1_cse, .x$w2_cse, method = "pearson") %>% 
                      broom::tidy()))

# Print the results with names
processed$corr_res_rt %>% 
  set_names(., processed$task) %>% 
  knitr::kable()
```

## Creating a correlation plot

```{r, eval= FALSE}
processed <-
  processed %>%
  mutate(corr_plot_rt = map2(corr_cse_data_rt, task,
                             ~ ggplot(.x, aes(x = w2_cse, y = w1_cse)) +
                                geom_jitter() +
                                geom_smooth(method = lm, color = "#7E9964", fill = "#C5E0B4") +
                                # scale_y_continuous(limits = c(500, 1000)) +
                                # scale_x_discrete(expand=c(1, 0)) +
                                ggtitle(stringr::str_to_title(.y)) +
                                xlab("rt CSE in wave 2 (ms)")+
                                ylab("rt CSE in wave 1 (ms)") +
                                theme(axis.line = element_line(color = "black"),
                                      panel.background = element_blank())))
```

## Creating correlation plots for the paper

```{r, eval= FALSE}
cowplot::plot_grid(plotlist = processed$corr_plot_rt)
```

## Saving the wave2 rt CSE figures

```{r, eval= FALSE}
ggsave("figures/weissman_replication_rt_corr.png", width = 14.4, height = 8, plot = last_plot())
```

## Creating a correlation plot in Hungarian

```{r, eval= FALSE}
processed <-
  processed %>%
  mutate(corr_plot_rt = map2(corr_cse_data_rt, task,
                             ~ ggplot(.x, aes(x = w2_cse, y = w1_cse)) +
                                geom_jitter() +
                                geom_smooth(method = lm, color = "#7E9964", fill = "#C5E0B4") +
                                # scale_y_continuous(limits = c(500, 1000)) +
                                # scale_x_discrete(expand=c(1, 0)) +
                                ggtitle(stringr::str_to_title(.y)) +
                                xlab("Reakcióidő CSE a 2. hullámban (ms)")+
                                ylab("Reakcióidő CSE az 1. hullámban (ms)") +
                                theme(axis.line = element_line(color = "black"),
                                      panel.background = element_blank())))
```

## Creating correlation plots for the paper in Hungarian

```{r, eval= FALSE}
cowplot::plot_grid(plotlist = processed$corr_plot_rt)
```

## Saving the wave2 rt CSE figures in Hungarian

```{r, eval= FALSE}
ggsave("figures/weissman_replication_rt_corr_hun.png", width = 14.4, height = 8, plot = last_plot())
```

## II. analysis: Testing whether the size of the CSE varies across tasks
### Creating the datatable

We are combining the effects (main congruency effect of current trial, main congruency effect of previous trial and interaction effect) for each task (primeprobe, Flanker, Stroop, Simon) in one datatable.

```{r, warning = FALSE}
w2_interaction_rt_data <- 
  processed %>% 
  select(task, w2_rt_effect_data) %>% 
  unnest(w2_rt_effect_data) %>% 
  mutate(task = as.factor(task))
```

### Testing the assumptions

We are testing the homogenity of variances.

```{r}
car::leveneTest(cseEffect ~ task, data = w2_interaction_rt_data)
```

The assumption of homogenity of variances is violated. Therefore, we are running a Kruskal Wallis H test instead of an ANOVA. 

### Running the analysis

We are running a  Kruskal-Wallis H test with task (levels: Prime-Probe, Flanker, Stroop, Simon) as the single factor, and the CSE index as the dependent variable to examine if the size of the effect differs across tasks.

```{r}
kruskal.test(cseEffect ~ task, data = w2_interaction_rt_data)
```

### Calculating pairwise comparisons

A Dunn’s test is used for pairwise comparisons.

```{r}
dunn_test <- DescTools::DunnTest(cseEffect ~ task, data = w2_interaction_rt_data)

dunn_test
```

Creating a tidy datatable from the Dunn test output.

```{r}
dunn_test <-
  dunn_test[[1]] %>% 
  as_tibble(rownames = "comparison") %>% 
  janitor::clean_names()
```

#### Bf analysis of pairwise comparisons
##### Preprocessing data for the Bf analyses

```{r}
# Stroop and Primeprobe comparison
stroop_primeprobe_comparison <- 
  t.test(cseEffect ~ task,
         data = filter(w2_interaction_rt_data,
                       task %in% c("stroop", "primeprobe"))) %>% 
  broom::tidy()

# Stroop and Simon comparison
stroop_simon_comparison <- 
  t.test(cseEffect ~ task,
         data = filter(w2_interaction_rt_data,
                       task %in% c("stroop", "simon"))) %>% 
  broom::tidy()

# Stroop and Flanker comparison
stroop_flanker_comparison <- 
  t.test(cseEffect ~ task,
         data = filter(w2_interaction_rt_data,
                       task %in% c("stroop", "flanker"))) %>% 
  broom::tidy()

# Primeprobe and Flanker comparison
primeprobe_flanker_comparison <- 
  t.test(cseEffect ~ task,
         data = filter(w2_interaction_rt_data,
                       task %in% c("primeprobe", "flanker"))) %>% 
  broom::tidy()

# Primeprobe and Simon comparison
primeprobe_simon_comparison <- 
  t.test(cseEffect ~ task,
         data = filter(w2_interaction_rt_data,
                       task %in% c("primeprobe", "simon"))) %>% 
  broom::tidy()

# Flanker and Simon comparison
flanker_simon_comparison <- 
  t.test(cseEffect ~ task,
         data = filter(w2_interaction_rt_data,
                       task %in% c("flanker", "simon"))) %>% 
  broom::tidy()
```

##### Running the analysis

A half-normal distribution is used with a mode of 0 and SD equal to half of the greater congruency effect of the two in any given pair as reported by Weissman et al. (2014).

Tasks in a descending order based on their congruency effect according to the original study:
Stroop > Primeprobe > Flanker > Simon

We are using a two-tailed test for the analysis.

###### Stroop and Primeprobe comparison

```{r}
# Bf Analysis
Bf(obtained = stroop_primeprobe_comparison$estimate,
   sd = stroop_primeprobe_comparison$estimate / stroop_primeprobe_comparison$statistic,
   dfdata = stroop_primeprobe_comparison$parameter,
   meanoftheory = 0,
   sdtheory = original$congruency[1] / 2,
   dftheory = 10^10,
   tail = 2)

# Finding the robustness region for the current incongruent follow up analysis
## Finding the lower boundary of the robustness region
Bf(obtained = stroop_primeprobe_comparison$estimate,
   sd = stroop_primeprobe_comparison$estimate / stroop_primeprobe_comparison$statistic,
   dfdata = stroop_primeprobe_comparison$parameter,
   meanoftheory = 0,
   sdtheory = 28.8,
   dftheory = 10^10,
   tail = 2)

## Finding the upper boundary of the robustness region
### The upper boundary is infinite, because the Bf supports the null model
```

###### Stroop and Simon comparison

```{r}
# Bf Analysis
Bf(obtained = stroop_simon_comparison$estimate,
   sd = stroop_simon_comparison$estimate / stroop_simon_comparison$statistic,
   dfdata = stroop_simon_comparison$parameter,
   meanoftheory = 0,
   sdtheory = original$congruency[1] / 2,
   dftheory = 10^10,
   tail = 2)

# Finding the robustness region for the current incongruent follow up analysis
## Finding the lower boundary of the robustness region
Bf(obtained = stroop_simon_comparison$estimate,
   sd = stroop_simon_comparison$estimate / stroop_simon_comparison$statistic,
   dfdata = stroop_simon_comparison$parameter,
   meanoftheory = 0,
     sdtheory = 37.7,
   dftheory = 10^10,
   tail = 2)

## Finding the upper boundary of the robustness region
## The upper boundary is infinite, because the Bf supports the null model
```

###### Stroop and Flanker comparison

```{r}
# Bf Analysis
Bf(obtained = stroop_flanker_comparison$estimate,
   sd = stroop_flanker_comparison$estimate / stroop_flanker_comparison$statistic,
   dfdata = stroop_flanker_comparison$parameter,
   meanoftheory = 0,
   sdtheory = original$congruency[1] / 2,
   dftheory = 10^10,
   tail = 2)

# Finding the robustness region for the current incongruent follow up analysis
## Finding the lower boundary of the robustness region
### The lower limit is 0, because the Bf is inconslusive

## Finding the upper boundary of the robustness region
Bf(obtained = stroop_flanker_comparison$estimate,
   sd = stroop_flanker_comparison$estimate / stroop_flanker_comparison$statistic,
   dfdata = stroop_flanker_comparison$parameter,
   meanoftheory = 0,
   sdtheory = 140,
   dftheory = 10^10,
   tail = 2)
```

###### Primeprobe and Flanker comparison

```{r}
# Bf Analysis
Bf(obtained = primeprobe_flanker_comparison$estimate,
   sd = primeprobe_flanker_comparison$estimate / primeprobe_flanker_comparison$statistic,
   dfdata = primeprobe_flanker_comparison$parameter,
   meanoftheory = 0,
   sdtheory = original$congruency[4] / 2,
   dftheory = 10^10,
   tail = 2)

# Finding the robustness region for the current incongruent follow up analysis
## Finding the lower boundary of the robustness region
Bf(obtained = primeprobe_flanker_comparison$estimate,
   sd = primeprobe_flanker_comparison$estimate / primeprobe_flanker_comparison$statistic,
   dfdata = primeprobe_flanker_comparison$parameter,
   meanoftheory = 0,
   sdtheory = 6.3,
   dftheory = 10^10,
   tail = 2)

## Finding the upper boundary of the robustness region
Bf(obtained = primeprobe_flanker_comparison$estimate,
   sd = primeprobe_flanker_comparison$estimate / primeprobe_flanker_comparison$statistic,
   dfdata = primeprobe_flanker_comparison$parameter,
   meanoftheory = 0,
   sdtheory = 101,
   dftheory = 10^10,
   tail = 2)
```

###### Primeprobe and Simon comparison

```{r}
# Bf Analysis
Bf(obtained = primeprobe_simon_comparison$estimate,
   sd = primeprobe_simon_comparison$estimate / primeprobe_simon_comparison$statistic,
   dfdata = primeprobe_simon_comparison$parameter,
   meanoftheory = 0,
   sdtheory = original$congruency[4] / 2,
   dftheory = 10^10,
   tail = 2)

# Finding the robustness region for the current incongruent follow up analysis
## Finding the lower boundary of the robustness region
Bf(obtained = primeprobe_simon_comparison$estimate,
   sd = primeprobe_simon_comparison$estimate / primeprobe_simon_comparison$statistic,
   dfdata = primeprobe_simon_comparison$parameter,
   meanoftheory = 0,
   sdtheory = 35,
   dftheory = 10^10,
   tail = 2)

## Finding the upper boundary of the robustness region
## The upper boundary is infinite, because the Bf supports the null model
```

###### Flanker and Simon comparison

```{r}
# Bf Analysis
Bf(obtained = flanker_simon_comparison$estimate,
   sd = flanker_simon_comparison$estimate / flanker_simon_comparison$statistic,
   dfdata = flanker_simon_comparison$parameter,
   meanoftheory = 0,
   sdtheory = original$congruency[3] / 2,
   dftheory = 10^10,
   tail = 2)

# Finding the robustness region for the current incongruent follow up analysis
## Finding the lower boundary of the robustness region
### The lower limit is 0, because the Bf is inconslusive

## Finding the upper boundary of the robustness region
Bf(obtained = flanker_simon_comparison$estimate,
   sd = flanker_simon_comparison$estimate / flanker_simon_comparison$statistic,
   dfdata = flanker_simon_comparison$parameter,
   meanoftheory = 0,
   sdtheory = 83,
   dftheory = 10^10,
   tail = 2)
```
# Accuracy analysis
## I. analysis: Testing whether the CSE was present in the different tasks
### Preprocessing data

We are calculating the accuracy for the analysis for each participant in each condition for each task in wave2.

```{r calculating mean dev acc}
processed <-
  processed %>% 
  mutate(w2_acc_data = map(w2_acc_data,
                        . %>% 
                          group_by(participant_id, isCongruent, isPrevCongruent) %>% 
                          summarise(AccConditionalMean = mean(isCorrect, na.rm = T)) %>% 
                          ungroup() %>% 
                          mutate(isCongruent = as_factor(isCongruent),
                                 isPrevCongruent = as_factor(isPrevCongruent),
                                 participant_id = as_factor(participant_id))))
```

We are calculating the main congruency effect of the current (n) trial, the main congruency effect of the previous trial (n-1) and the interaction effect (CSE) between them for each participant in wave2.

```{r}
processed <-
  processed %>% 
  mutate(w2_acc_effect_data = map(w2_acc_data,
                              . %>% 
                                mutate(condition = case_when(isPrevCongruent == 0L & isCongruent == 0L ~ "ii",
                                                             isPrevCongruent == 0L & isCongruent == 1L ~ "ic",
                                                             isPrevCongruent == 1L & isCongruent == 0L ~ "ci",
                                                             isPrevCongruent == 1L & isCongruent == 1L ~ "cc",
                                                             TRUE ~ NA_character_)) %>% 
                                select(-isPrevCongruent, -isCongruent) %>% 
                                spread(key = condition, value = AccConditionalMean) %>% 
                                mutate(congruency_effect =  ((cc + ic) / 2) - ((ci + ii) / 2),
                                previous_congruency_effect = ((ci + cc) / 2) - ((ii + ic) / 2),
                                interaction_effect = (cc - ci) - (ic - ii))))
```

### Running the analysis on wave2 data

We are running a 2 × 2 repeated-measures ANOVA per task with accuracy as dependent variable. The two factors of the ANOVA are Previous Trial Congruency (congruent, incongruent) and Current Trial Congruency (congruent, incongruent).

```{r}
processed <-
  processed %>% 
  mutate(w2_anova_acc = map(w2_acc_data,
                        ~ aov(AccConditionalMean ~ isCongruent * isPrevCongruent + Error(participant_id / (isCongruent * isPrevCongruent)), data = .x)))

# Print the results with names
processed$w2_anova_acc %>% 
  set_names(., processed$task) %>% 
  map(., summary)
```

None of the interaction effects are significant, therefore we will not run any follow up analysis for the accuracy analysis.

We are calculating the partial eta square as an effect size estimate for the ANOVA.

```{r}
processed <-
  processed %>% 
  mutate(w2_anova_acc_eta = map(w2_anova_acc,
                            ~ eta_sq(.x, partial = TRUE)))

# Print results with names
processed$w2_anova_acc_eta %>% 
  set_names(., processed$task)
```

### Calculating Bayes factors
#### Preprocessing data for the Bayes factor analysis

We are substracting the F values for each effect (main congruency effect of current trial, main congruency effect of previous trial and interaction effect) from the ANOVA.

```{r}
processed <-
  processed %>% 
  mutate(w2_anova_acc_f = map(w2_anova_acc,
                          . %>%
                            broom::tidy() %>% 
                            select(term, statistic) %>% 
                            transmute(term = case_when(term == "isCongruent" ~ "mainEffectIsCongruent",
                                                       term == "isPrevCongruent" ~ "mainEffectIsPrevCongruent",
                                                       term == "isCongruent:isPrevCongruent" ~ "interactionEffect",
                                                       term == "Residuals" ~ term),
                                      fValue = statistic)))
```

We are calculating the mean effects (main congruency effect of current trial, main congruency effect of previous trial and interaction effect) for each task.

```{r}
processed <-
  processed %>% 
  mutate(w2_anova_acc_raw_effect = map(w2_acc_effect_data,
                                   . %>% 
                                     summarise(mainEffectIsCongruent = mean(congruency_effect, na.rm = T),
                                               mainEffectIsPrevCongruent = mean(previous_congruency_effect, na.rm = T),
                                               interactionEffect = mean(interaction_effect, na.rm = T),
                                               nParticipant = n()) %>%
                                     gather(key = "term", value = "rawEffect", -nParticipant)))
```

We are adding the calucalted F-values for each effect to the calculated mean effects.

```{r}
processed <-
  processed %>% 
  mutate(w2_anova_acc_raw_effect = map2(w2_anova_acc_raw_effect, w2_anova_acc_f,
                                    ~ inner_join(.x, .y, by = "term") %>% 
                                      mutate(se = abs(rawEffect / sqrt(fValue)))))
```

Preprocessing effect sizes that Weissman et al. (2014) found for the H1 model of the Bayes factor analysis.

```{r}
original_acc_effect <-
  original %>% 
  filter(measure == "acc") %>% 
  select(task, congruency, cse) %>% 
  gather(key = "term", value = "originalRawEffect", -task) %>%
  mutate(term = case_when(term == "congruency" ~ "mainEffectIsCongruent",
                          term == "cse" ~ "interactionEffect")) %>% 
  group_by(task) %>% 
  nest() %>% 
  rename(original_effect_accuracy = data)
```

Joining the effect sizes of the replicated study with the effect sizes of the current study.

```{r}
processed <-
  processed %>%
  mutate(task = as.character(task)) %>% # vector needs to be character class (instead of a list) for joining
  left_join(., original_acc_effect, by = "task") %>% 
  mutate(w2_anova_acc_bf_effect = map2(w2_anova_acc_raw_effect, original_effect_accuracy,
                              ~ left_join(.x, .y, by = "term")))
```

Parameters for calculating the Bayes-factor

```{r}
map(processed$w2_anova_acc_bf_effect, print)
```

#### Calculating the Bayes factor
##### For the interaction effect

A half-normal distribution is used with a mode of 0 and a SD equal to the half of the congruency effect (in ms) for the particular task in the original data set by Weissman et al. (2014) to model the prediction of the interaction effect. 

```{r}
processed <-
  processed %>% 
  mutate(w2_bf_interaction_acc = map(w2_anova_acc_bf_effect,
                                 ~ Bf(sd = .x$se[3],
                                      obtained = .x$rawEffect[3],
                                      dfdata = .x$nParticipant[1] - 1,
                                      meanoftheory = 0,
                                      sdtheory = .x$originalRawEffect[1] / 2,
                                      dftheory = 10^10,
                                      tail = 1)))

# Print results with names
processed$w2_bf_interaction_acc %>% 
  set_names(., processed$task)
```

##### For the main congruency effect of the current trial

To test the congruency main effect, the SD of the H1 model is set to the congruency effect reported by Weissman et al. (2014) for the given task. The other settings stay the same.

```{r}
processed <-
  processed %>% 
  mutate(w2_bf_congruency_acc = map(w2_anova_acc_bf_effect,
                                ~ Bf(sd = .x$se[1],
                                     obtained = .x$rawEffect[1],
                                     dfdata = .x$nParticipant[1] - 1,
                                     meanoftheory = 0,
                                     sdtheory = .x$originalRawEffect[1],
                                     dftheory = 10^10,
                                     tail = 1))) 

# Print results with names
processed$w2_bf_congruency_acc %>% 
  set_names(., processed$task)
```

### Follow up simple effects analysis
#### Preprocessing data

Saving the data of the task (simon) with significant interaction between current trial congruency and previous trial congruency.

```{r}
simon <- processed$w2_acc_effect_data[[4]]
```

#### Running the analysis

If the Bayes factor is greater than the preset threshold of B = 3 for the interaction effect in a given task we run a simple effects analyses, contrasting current-congruent congruent (cC) and current-incongruent congruent (iC) trials.

```{r current congruent follow up comparison for acc}
w2_current_congruent <- 
  t.test(simon$cc, simon$ic, paired = TRUE) %>% 
  broom::tidy()

w2_current_congruent %>% knitr::kable()
```

current-congruent incongruent (cI) and current-incongruent incongruent (iI) trials in another.

```{r current incongruent follow up comparison for acc}
w2_current_incongruent <- 
  t.test(simon$ci, simon$ii, paired = TRUE) %>% 
  broom::tidy()

w2_current_incongruent %>% knitr::kable()
```

#### Calculating the Bayes factor for the follow up analysis

The prior H1 model is a half-normal distribution with a mode of 0 and an SD equal to half of the CSE estimate for that given task, i.e., the originally reported congruency effect divided by four.

#### Current congruent follow-up comparison

```{r}
Bf(sd = w2_current_congruent$estimate / w2_current_congruent$statistic,
   obtained = w2_current_congruent$estimate,
   dfdata = w2_current_congruent$parameter,
   meanoftheory = 0,
   sdtheory = processed$w2_anova_acc_bf_effect[[4]]$originalRawEffect[1] / 4,
   dftheory = 10^10,
   tail = 1)
```

#### Current icongruent follow-up comparison

```{r}
Bf(sd = w2_current_incongruent$estimate / w2_current_incongruent$statistic,
   obtained = w2_current_incongruent$estimate,
   dfdata = w2_current_incongruent$parameter,
   meanoftheory = 0,
   sdtheory = processed$w2_anova_acc_bf_effect[[4]]$originalRawEffect[1] / 4,
   dftheory = 10^10,
   tail = 1)
```

***
# Testing correlation of CSE between wave1 and wave2 accuracy data

```{r}
processed <-
  processed %>% 
  mutate(corr_data_acc = map(acc_data,
                       . %>%
                          group_by(wave, participant_id, isCongruent, isPrevCongruent) %>%
                          summarise(AccConditionalMean = mean(isCorrect, na.rm = T)) %>%
                          ungroup() %>%
                          mutate(isCongruent = as.factor(isCongruent),
                                 isPrevCongruent = as.factor(isPrevCongruent),
                                 participant_id = as.factor(participant_id))))
```

## We are calculating the main congruency effect of the current (n) trial, the main congruency effect of the previous trial (n-1) and the interaction effect (CSE) between them for each participant in both waves.

```{r}
processed <-
  processed %>% 
  mutate(corr_effect_data_acc = map(corr_data_acc,
                              . %>%
                                 mutate(condition = case_when(isPrevCongruent == 0L & isCongruent == 0L ~ "ii",
                                                             isPrevCongruent == 0L & isCongruent == 1L ~ "ic",
                                                             isPrevCongruent == 1L & isCongruent == 0L ~ "ci",
                                                             isPrevCongruent == 1L & isCongruent == 1L ~ "cc",
                                                             TRUE ~ NA_character_)) %>%
                                 select(-isPrevCongruent, -isCongruent) %>%
                                 spread(key = condition, value = AccConditionalMean) %>%
                                 mutate(congruencyEffect = ((cc + ic) / 2) - ((ci + ii) / 2),
                                        prevCongruencyEffect = ((ci + cc) / 2) - ((ii + ic) / 2),
                                        cseEffect = (cc - ci) - (ic - ii))))

```

## Preprocessing df for correlation calculation

```{r}
processed <-
   processed %>% 
   mutate(corr_cse_data_acc = map(corr_effect_data_acc,
                              . %>% 
                                 select(wave, participant_id, cseEffect) %>%
                                 spread(key = wave, value = cseEffect) %>% 
                                 rename(w1_cse = `1`, w2_cse = `2`)))
```

## Calculating correlation

```{r}
processed <-
  processed %>% 
  mutate(corr_res_acc = map(corr_cse_data_acc,
                    ~ cor.test(.x$w1_cse, .x$w2_cse, method = "pearson") %>% 
                      broom::tidy()))

# Print the results with names
processed$corr_res_acc %>% 
  set_names(., processed$task) %>% 
  knitr::kable()
```

## Creating a correlation plots

```{r, eval= FALSE}
processed <-
  processed %>%
  mutate(corr_plot_acc = map2(corr_cse_data_acc, task,
                           ~ ggplot(.x, aes(x = w2_cse, y = w1_cse)) +
                             geom_jitter() +
                              geom_smooth(method = lm, color = "#7E9964", fill = "#C5E0B4") +
                             # scale_y_continuous(limits = c(500, 1000)) +
                             # scale_x_discrete(expand=c(1, 0)) +
                             ggtitle(stringr::str_to_title(.y)) +
                             xlab("accuracy CSE in wave 2")+
                             ylab("accuracy CSE in wave 1") +
                             theme(axis.line = element_line(color = "black"),
                                   panel.background = element_blank())))
```

## Creating correlation plots for the paper

```{r, eval= FALSE}
cowplot::plot_grid(plotlist = processed$corr_plot_acc)
```

## Saving the wave2 acc CSE figures

```{r, eval= FALSE}
ggsave("figures/weissman_replication_acc_corr.png", width = 14.4, height = 8, plot = last_plot())
```

## Creating a correlation plot in Hungarian

```{r, eval= FALSE}
processed <-
  processed %>%
  mutate(corr_plot_acc = map2(corr_cse_data_acc, task,
                             ~ ggplot(.x, aes(x = w2_cse, y = w1_cse)) +
                                geom_jitter() +
                                geom_smooth(method = lm, color = "#7E9964", fill = "#C5E0B4") +
                                # scale_y_continuous(limits = c(500, 1000)) +
                                # scale_x_discrete(expand=c(1, 0)) +
                                ggtitle(stringr::str_to_title(.y)) +
                                xlab("Pontosság CSE a 2. hullámban")+
                                ylab("Pontosság CSE az 1. hullámban") +
                                theme(axis.line = element_line(color = "black"),
                                      panel.background = element_blank())))
```

## Creating correlation plots for the paper in Hungarian

```{r, eval= FALSE}
cowplot::plot_grid(plotlist = processed$corr_plot_acc)
```

## Saving the wave2 rt CSE figures in Hungarian

```{r, eval= FALSE}
ggsave("figures/weissman_replication_acc_corr_hun.png", width = 14.4, height = 8, plot = last_plot())
```
